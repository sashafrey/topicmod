=======================
Introduction to BigARTM
=======================

BigARTM is a library that enables you to infer `topic models`_.

The following table lists key features of the library.

============== ====================================================================
Regularized    As it follows from the name, BigARTM is based on a novel technique,
               `Additive Regularization of Topic Models`_.
               This allows you to combine several requirements in one topic model.

Online         BigARTM avoids storing the entire text collection
               in the main memory. Instead the collection is split into
               small subsets called 'batches', and loads a limited
               number of batches at a time.

Parallel       BigARTM can concurrently process several batches,
               and by doing so it substantially improves the throughput
               on multi-core machines. By placing all processing into
               a single process BigARTM achieves high level of concurrency
               without consuming any additional memory.

Distributed    BigARTM is able to distribute all CPU-intensive processing
               to several machines, connected by network.

Extensible API BigARTM comes with an API in C++ and Python,
               but can be extended for all other languages
               that have an implementation of `Google Protocol Buffers`_.

Cross-platform BigARTM is known to be compatible with gcc, clang and the Microsoft
               compiler (VS 2012). We have tested our library on Windows, Ubuntu
               and Fedora.

Open source    BigARTM is released under the `New BSD License`_.
               If you plan to use our library commercially, please beware that
               BigARTM depends on ZeroMQ. Please, make sure to review
               `ZeroMQ license`_.
============== ====================================================================

.. _Additive Regularization of Topic Models: http://www.machinelearning.ru/wiki/images/1/1f/Voron14aist.pdf
.. _topic models: http://en.wikipedia.org/wiki/Topic_model
.. _Google Protocol Buffers: https://code.google.com/p/protobuf/
.. _New BSD license: http://opensource.org/licenses/BSD-3-Clause
.. _ZeroMQ license: http://zeromq.org/area:licensing
